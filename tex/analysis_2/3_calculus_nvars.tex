\chapter{Calcolo differenziale per funzioni in più variabili}

\section{Funzioni differenziabili}

\begin{definition}
    [Derivata parziale]
    Sia $f: A \subseteq \R^n \to \R$. Si definisce derivata parziale $j$-esima di $f$ in $\vb{x_0}$ il valore del seguente limite, se esiste finito:
    $$
        \frac{\partial f}{\partial x_j} (\vb{x_0}) = \displaystyle \lim_{h\to 0} \frac{f(\vb{x_0} + h\vb{\hat{e}_j}) - f(\vb{x_0})}{h} \in \R
    $$
    dove $\vb{\hat{e}_j}$ è il j-esimo vettore della base canonica.
\end{definition}

\begin{definition}
    [Gradiente]
    Siano $A \subseteq \R^n$ un aperto, $\vb{x_0} \in A$ e $f:A \to \R$. Se esistono $\frac{\partial f}{\partial x_1}(\vb{x_0}),\dots,\\\frac{\partial f}{\partial x_n}(\vb{x_0})$, allora si definisce gradiente di $f$ in $\vb{x_0}$ il vettore $\bm{\nabla}f = \left( \frac{\partial f}{\partial x_1} (\vb{x_0}), \dots, \frac{\partial f}{\partial x_n}(\vb{x_0}) \right)$.
\end{definition}

\begin{definition}
    [Derivata direzionale]
    Siano $A \subseteq \R^n$ un aperto, $\vb{x_0} \in A$, $f:A \to \R$ e $\bm{\hat{\nu}} = (\nu_1,\dots,\nu_n) \in \R^n \tc \norm{\bm{\hat{\nu}}}=1$. Si definisce derivata direzionale di $f$ in $\vb{x_0}$ rispetto alla direzione $\bm{\hat{\nu}}$ il valore del seguente limite, se esiste finito:
    $$
        \frac{\partial f}{\partial \bm{\hat{\nu}}} (\vb{x_0}) = \displaystyle \lim_{h\to 0} \frac{f(\vb{x_0} + h\bm{\hat{\nu}}) - f(\vb{x_0})}{h} \in \R
    $$
\end{definition}

\begin{remark}
    La derivabilità in tutte le direzioni non assicura la continuità della funzione $f$ nel punto $\vb{x_0}$. Essa implica infatti solo che $f$ sia continua in $\vb{x_0}$ per ogni restrizione a rette passanti in $\vb{x_0}$, ma non in tutto un intorno di $\vb{x_0}$. È necessario un concetto più forte che viene definito di seguito.
\end{remark}

\begin{definition}
    [Funzione differenziabile]
    Siano $A \subseteq \R^n$ un aperto, $\vb{x_0} \in A$ e $f:A \to \R$. La funzione $f$ è differenziabile in $\vb{x_0}$ se esiste $\vb{m} = (m_1,\dots,m_n) \in \R^n \tc f(\vb{x}) = f(\vb{x_0}) + \ip{\vb{m}}{\vb{x} - \vb{x_0}} + o(\norm{\vb{x} - \vb{x_0}}) \with \norm{\vb{x}-\vb{x_0}}\to 0$.
\end{definition}

\begin{definition}
    [Operatore differenziale]
    Si definisce operatore differenziale e si indica con $\dd{f}_{\vb{x_0}} : \R^n \to \R$ l'operatore $\dd{f}_{\vb{x_0}}(\vb{h})=\ip{\vb{m}}{\vb{h}}$.
\end{definition}

\begin{theorem}
    [Proprietà delle funzioni differenziabili]
    Siano $A \subseteq \R^n$ un aperto, $\vb{x_0} \in A$ e $f:A \to \R$ una funzione differenziabile. Allora:
    \begin{enumerate}
        \item $f$ è continua in $\vb{x_0}$
        \item $f$ è derivabile parzialmente in $\vb{x_0}$ e $\vb{m} = \bm{\nabla}f(\vb{x_0})$
        \item $f$ è derivabile in qualunque direzione $\bm{\hat{\nu}} \tc \norm{\bm{\hat{\nu}}}=1$ e $\frac{\partial f}{\partial \bm{\hat{\nu}}} = \ip{\grad f(\vb{x_0})}{\bm{\hat{\nu}}}$
    \end{enumerate}
\end{theorem}

\begin{proof}
    Si dimostra ciascun punto separatamente.
    \begin{enumerate}
        \item Si verifica che la distanza fra $f(\vb{x})$ e $f(\vb{x_0})$ tende a $0$ se $\vb{x}$ tende a $\vb{x_0}$.
        \begin{align*}
            \abs{f(\vb{x})-f(\vb{x_0})}&=\abs{\innerproduct{\vb{m}}{\vb{x}-\vb{x_0}}+o(\norm{\vb{\vb{x}-\vb{x_0}}})}\leq\\
            &\leq\abs{\innerproduct{\vb{m}}{\vb{\vb{x}-\vb{x_0}}}}+o(\norm{\vb{\vb{x}-\vb{x_0}}})\leq\\
            &\leq\norm{\vb{m}}\norm{\vb{x}-\vb{x_0}}+o(\norm{\vb{x}-\vb{x_0}})\xrightarrow{\vb{x}\to\vb{x_0}} 0
        \end{align*}

        \item Si studi il limite che definisce la derivata parziale $j$-esima di $f$ in $\vb{x_0}$.
        \begin{align*}
            \frac{\partial f}{\partial x_j}&=\lim_{t\to 0}\frac{f(\vb{x_0}+t\hat{\vb{e}}_j)-f(\vb{x_0})}{t}=\\
            &=\lim_{t\to 0}\frac{\innerproduct{\vb{m}}{t\hat{\vb{e}}_j} + o(\abs{t})}{t}=\\
            &=\innerproduct{\vb{m}}{\hat{\vb{e}}_j}=m_j
        \end{align*}
        La derivata parziale di $f$ rispetto a $x_j$ è la $j$-esima componente del vettore $\vb{m}$, quindi $\vb{m}=\grad f(\vb{x_0})$.

        \item Come nel punto 2, si studi il limite che definisce la derivata direzionale di $f$ in $\vb{x_0}$.
        \begin{align*}
            \frac{\partial f}{\partial \hat{\bm \nu}}&=\lim_{t\to 0}\frac{f(\vb{x_0}+t\hat{\bm \nu})-f(\vb{x_0})}{t}=\\
            &=\lim_{t\to 0}\frac{\innerproduct{\grad f(\vb{x_0})}{t\hat{\bm \nu}} + o(\abs{t})}{t}=\\
            &=\innerproduct{\grad f(\vb{x_0})}{\hat{\bm \nu}}
        \end{align*}
    \end{enumerate}
\end{proof}

\begin{definition}
    [Insieme di livello]
    Siano $A \subseteq \R^n$ un aperto, $f:A \to \R$ e $c \in \R$. Si definisce insieme di livello l'insieme $M_c = \{ \vb{x} \in A : f(\vb{x})=c\}\subseteq A$.
\end{definition}

\begin{theorem}
    [del differenziale totale]
    Siano $A \subseteq \R^n$ un aperto e $f: A \to \R$ derivabile in $A$. Se $\frac{\partial f}{\partial x_j} (\vb{x})$ sono continue in $\vb{x_0} \ \forall j \in [n]$, allora $f$ è differenziabile in $\vb{x_0}$.
\end{theorem}

\begin{proof}[Dimostrazione per n=2.]
    % TODO
\end{proof}

\begin{theorem}
    [Funzioni a gradiente nullo]
    Sia $A \subseteq \R^n$ aperto e connesso. Se $f: A \to \R$ è derivabile in $A$ e $\grad f (\vb{x})=(0,\dots,0) \ \forall \vb{x} \in A$, allora $f$ è costante.
\end{theorem}

\begin{proof}
    % TODO
\end{proof}

\section{Derivate di ordine superiore}

\begin{definition}
    [Derivata di ordine $k$]
    Siano $A \subseteq \R^n$ un aperto, $\vb{x_0} \in A$ e $f:A \to \R$. Se $\displaystyle \exists \frac{\partial f}{\partial x_{i_1}}, \frac{\partial^2 f}{\partial x_{i_1} \partial x_{i_2}},\dots,\frac{\partial ^{k-1}f}{\partial x_{i_1} \cdots \partial x_{i_{k-1}}} : B_\varepsilon(\vb{x_0}) \to \R$, si definisce derivata $k$-esima di $f$ in $\vb{x_0}$ rispetto a $x_{i_1},\dots,x_{i_{k}}$ il valore del seguente limite se esiste finito:
    $$
        \lim_{h\to 0}\frac{\frac{\partial^{k-1}f}{\partial x_{i_1}\cdots \partial x_{i_{k-1}}}(\vb{x_0}+ h \vb{\hat{e}_{i_k}})- \frac{\partial^{k-1}f}{\partial x_{i_1}\cdots \partial x_{i_{k-1}}}(\vb{x_0})}{h} \in \R
    $$
\end{definition}

\begin{definition}
    [Insieme $\C{k}(A, \R)$]
    Si definisce l'insieme delle funzioni derivabili con continuità $k$ volte in $A$:
    $$
        \displaystyle \C{k}(A,\R) = \left\{ f: A \to \R \tc \ \exists \frac{\partial f}{\partial x_i},\dots,\frac{\partial ^2 f}{\partial x_i \partial x_j}, \dots, \frac{\partial ^k f}{\partial x_{i_1}\cdots\partial x_{i_k}} \text{ continue in } A \right\}
    $$
\end{definition}

\begin{remark}
    Si noti che devono essere continue tutte le combinazioni possibili di derivate, che crescono molto velocemente ($n^k$).
\end{remark}

\begin{theorem}
    [di Schwarz]\label{thm:schwarz}
    Siano $A \subseteq \R^n$ un aperto e $f: A \to \R$ derivabile due volte in $A$. Se $\frac{\partial ^2 f}{\partial x_i \partial x_j}$ e $\frac{\partial^2 f}{\partial x_j \partial x_i}$ sono continue in $\vb{x_0} \in A$, allora
    $$
        \frac{\partial ^2 f}{\partial x_i \partial x_j}(\vb{x_0}) = \frac{\partial^2  f}{\partial x_j \partial x_i}(\vb{x_0})
    $$
\end{theorem}

\begin{proof}
    [Dimostrazione per n=2.] % TODO
\end{proof}

\begin{definition}
    [Matrice hessiana]
    Siano $A \subseteq \R^n$ un aperto e $f: A \to \R$ derivabile due volte in $A$. Si definisce matrice hessiana di $f$ in $\vb{x_0}$ la matrice
    $$
        H_f(\vb{x_0}) =
        \begin{bmatrix}
            \grad \frac{\partial f}{\partial x_1}(\vb{x_0})\\
            \vdots\\
            \grad \frac{\partial f}{\partial x_n}(\vb{x_0})
        \end{bmatrix}
    $$
\end{definition}

\begin{remark}
    Per il teorema \ref{thm:schwarz}, se $f$ è $\C{2}$ in $\vb{x_0} \in A$, allora $H_f(\vb{x_0})$ è simmetrica.
\end{remark}

\begin{theorem}
    [Formula di Taylor di ordine $k$]
    Sia $A \subseteq \R^n$ un aperto. Se $f \in \C{k}(A, \R)$, allora vale la seguente
    \begin{align*}
        f(\vb{x_0}+ \vb{h})= f(\vb{x_0})&+\sum_{j=1}^{n}\frac{\partial f}{\partial x_j}(\vb{x_0})h_j + \frac{1}{2}\sum_{i,j=1}^{n}\frac{\partial^2 f}{\partial x_i \partial x_j}(\vb{x_0})h_ih_j+\cdots+\\
        &+\frac{1}{k!}\sum_{i_1,\dots,i_k=1}^n\frac{\partial^k}{\partial x_{i_1}\cdots\partial x_{i_k}}(\vb{x_0})h_{i_1}\cdots h_{i_k} +\\
        &+o (\norm{\vb{h}}^k) \with \norm{\vb{h}} \to 0
    \end{align*}
    \qed
\end{theorem}

\begin{remark}
    In particolare, per $n=2$ vale
    $$
        f(\vb{x_0} + \vb{h}) = f(\vb{x_0})+\ip{\grad f(\vb{x_0})}{\vb{h}} + \frac{1}{2}\ip{\vb{h}}{H_f(\vb{x_0})\vb{h}}+o(\norm{\vb{h}}^2) \with \norm{\vb{h}} \to 0
    $$
\end{remark}

\section{Punti critici liberi}

\begin{definition}
    [Massimo (minimo) locale]\label{def:minmax}
    Sia $A \subseteq \R^n$ e $f: A \to \R$. Il punto $\vb{x_0}$ è un punto di massimo (minimo) locale per $f$ se $\exists \delta > 0 \tc f(\vb{x}) \leq f(\vb{x_0})\ (f(\vb{x})\geq f(\vb{x_0})) \ \forall \vb{x} \in A \cap B_\delta (\vb{x_0})$.
\end{definition}

\begin{definition}
    [Punto di sella]\label{def:sella}
    Sia $A \subseteq \R^n$ e $f: A \to \R$. Il punto $\vb{x_0}$ è un punto di sella per $f$ se $\grad f(\vb{x_0})=\vb{0}$ e $\forall \varepsilon > 0 \ \exists \vb{x_1}, \vb{x_2} \in A \cap B_\varepsilon(\vb{x_0}) \tc f(\vb{x_1}) > f(\vb{x_0}) > f(\vb{x_2})$.
\end{definition}

\begin{remark}
    Si noti che nelle definizioni \ref{def:minmax} e \ref{def:sella} non si richiede alcuna regolarità di $f$ e alcuna proprietà particolare di $A$.
\end{remark}

\begin{definition}
    [Punto critico (o stazionario)]
    Siano $A \subseteq \R^n$ un aperto e $f: A\to \R$. $\vb{x_0} \in A$ è un punto critico (o stazionario) di $f$ se $\exists \grad f(\vb{x_0})$ e $\grad f(\vb{x_0})=\vb{0}$.
\end{definition}

\begin{theorem}
    [di Fermat]
    Sia $A \subseteq \R^n$ un aperto e $f: A \to \R$. Se $\vb{x_0} \in A$ è massimo o minimo locale per $f$ ed esiste il gradiente di $f$ in $\vb{x_0}$, allora $\grad f(\vb{x_0})=\vb{0}$, cioè $\vb{x_0}$ è punto critico di $f$.
\end{theorem}

\begin{proof}
    % TODO
\end{proof}

\subsection{Forme quadratiche}

Sia $M \in \mathcal{M}_{n \times n}(\R)$ una matrice quadrata di ordine $n$. La seguente espressione si chiama forma quadratica associata alla matrice $M$:
$$
    q_M(\vb{h}) = \ip{\vb{h}}{M\vb{h}} \in \R
$$
La forma quadratica può essere:
\begin{itemize}
    \item Definita positiva se $\forall \vb{h}\neq \vb{0}, \ q_M(\vb{h})> 0$
    \item Definita negativa se $\forall \vb{h}\neq \vb{0}, \ q_M(\vb{h}) < 0$
    \item Semidefinita positiva se $\forall \vb{h}\in \R^n, \ q_M(\vb{h}) \geq 0$ e $\exists \vb{k} \tc q_M(\vb{k})=0$
    \item Semidefinita negativa se $\forall \vb{h}\in \R^n, \ q_M(\vb{h}) \leq 0$ e $\exists \vb{k} \tc q_M(\vb{k})=0$
    \item Indefinita se $\exists \vb{h}, \vb{k} \in \R^n \tc q_M(\vb{h}) < 0 < q_M(\vb{k})$
\end{itemize}

Matrici diverse possono essere associate alla stessa forma quadratica, infatti è sufficiente che abbiano gli stessi elementi sulla diagonale e che la somma $a_{ij}+a_{ji}=b_{ij}+b_{ji} \ \forall i\neq j\with i,j \in [n]$. Fra tutte le matrici associate alla stessa forma quadratica, ci si può restringere alle matrici simmetriche (che sono sempre diagonalizzabili!), per cui esistono criteri di classificazione efficaci.

\begin{theorem}
    [Classificazione delle forme quadratiche e segno degli autovalori]
    Sia $A \in \mathcal{M}_{n\times n}(\R)$ tale che $A=A^T$ e $q_A$ la forma quadratica associata ad $A$. Sia la coppia $(p,q)$ la segnatura della matrice $A$, dove $p$ rappresenta la somma delle molteplicità algebriche degli autovalori positivi e $q$ la somma delle molteplicità algebriche degli autovalori negativi. Allora:
    \begin{enumerate}
        \item $q_A$ è definita positiva $\iff (p,q)=(n,0)$
        \item $q_A$ è definita negativa $\iff (p,q)=(0,n)$
        \item $q_A$ è semidefinita positiva $\iff (p,q)=(m,0) \with 0< m < n$
        \item $q_A$ è semidefinita negativa $\iff (p,q)=(0,l) \with 0< l < n$
        \item $q_A$ è indefinita $\iff (p,q)=(m,l) \with 0<m<n,0<l<n$
        \qed
    \end{enumerate}
\end{theorem}

\begin{theorem}
    [Criterio di Sylvester]
    Sia $A \in \mathcal{M}_{n\times n}(\R) \tc A=A^T\neq \vb{0}$ e sia $A_k$ il minore principale nord-ovest di ordine $k$ ottenuto selezionando le prime $k$ righe e le prime $k$ colonne di $A$. Allora la matrice $A$ è:
    \begin{enumerate}
        \item Definita positiva $\iff \det A_k > 0 \ \forall k \in [n]$
        \item Definita negativa $\iff \det A_k < 0$ se $k$ è dispari e $\det A_k > 0$ se $k$ è pari $ \ \forall k \in [n]$
        \item Semidefinita positiva $\iff \det A_k \geq 0 \ \forall k \in [n]$ e $\exists j \in [n] \tc \det A_j = 0$
        \item Semidefinita negativa $\iff \det A_k \leq 0$ se $k$ è dispari e $\det A_k \geq 0$ se $k$ è pari $ \ \forall k \in [n]$ e $\exists j \in [n] \tc \det A_j=0$
        \item Indefinita altrimenti
        \qed
    \end{enumerate}
\end{theorem}

\subsection{Classificazione dei punti critici}

\begin{theorem}
    [Classificazione con la matrice hessiana]
    Sia $f \in \C{2}(A, \R) \with A\subseteq \R^n$ aperto. Allora:
    \begin{enumerate}
        \item Se $\vb{x_0} \in A$ è punto di minimo locale per $f$, allora $\grad f(\vb{x_0})=\vb{0}$ e $H_f(\vb{x_0})$ è o definita positiva o semidefinita positiva
        \item Se $\vb{x_0} \in A$ è punto di massimo locale per $f$, allora $\grad f(\vb{x_0})=\vb{0}$ e $H_f(\vb{x_0})$ è o definita negativa o semidefinita negativa
        \item Se $\grad f(\vb{x_0})=\vb{0}$ e $H_f(\vb{x_0})$ è definita positiva, allora $\vb{x_0}$ è punto di minimo locale per $f$
        \item Se $\grad f(\vb{x_0})=\vb{0}$ e $H_f(\vb{x_0})$ è definita negativa, allora $\vb{x_0}$ è punto di massimo locale per $f$
        \item Se $\grad f(\vb{x_0})=\vb{0}$ e $H_f(\vb{x_0})$ è indefinita, allora $\vb{x_0}$ è un punto di sella per $f$
    \end{enumerate}
\end{theorem}

\begin{proof}
    % TODO
\end{proof}