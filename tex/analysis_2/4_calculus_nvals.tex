\chapter{Calcolo differenziale per funzioni a valori vettoriali}

\section{Funzioni derivabili e differenziabili}

\begin{definition}
    [Funzione derivabile]
    Sia $\vecf=(f_1,\dots,f_k): A\subseteq \R^n \to \R^k \with A$ aperto. $\vecf$ è derivabile in $\vb{x_0} \in A$ se $\exists \frac{\partial f_1}{\partial x_i}(\vb{x_0}),\dots,\frac{\partial f_k}{\partial x_i}(\vb{x_0}) \in \R \ \forall i \in [n]$. In questo caso si definisce la matrice jacobiana di $\vecf$ in $\vb{x_0}$ come segue:
    \begin{equation*}
        J_{\vecf}(\vb{x_0})=
        \begin{bmatrix}
            \grad f_1 (\vb{x_0})\\
            \vdots \\
            \grad f_k (\vb{x_0})
        \end{bmatrix}
        \in \mathcal{M}_{k\times n}(\R)
    \end{equation*}
\end{definition}

\begin{definition}
    [Funzione differenziabile]
    Sia $\vecf=(f_1,\dots,f_k): A\subseteq \R^n \to \R^k \with A$ aperto. $\vecf$ è differenziabile in $\vb{x_0} \in A$ se $\exists M \in \mathcal{M}_{k\times n}(\R)$ tale che
    \begin{equation*}
        \vecf(\vb{x_0} + \vb{h})= \vecf(\vb{x_0}) + M\vb{h} + \bm o (\norm{\vb{h}}) \in \R^k \with \norm{\vb{h}}\to 0
    \end{equation*}
\end{definition}

\begin{theorem}
    [Condizioni per differenziabilità]
    Sia $A \subseteq \R^n$ un aperto e $\vecf= (f_1,\dots,f_k):A \to \R^k$.
    \begin{enumerate}
        \item $\vecf$ è differenziabile in $\vb{x_0} \in A \iff f_1,\dots,f_k$ sono differenziabili in $\vb{x_0} \in A$. In tal caso
        \begin{equation*}
            M=J_{\vecf}(\vb{x_0})=
            \begin{bmatrix}
                \grad f_1(\vb{x_0})\\
                \vdots\\
                \grad f_k(\vb{x_0})
            \end{bmatrix}
            \in \mathcal{M}_{k\times n}(\R)
        \end{equation*}
        \item Se $\vecf$ è differenziabile in $\vb{x_0} \in A$, allora $\vecf$ è continua in $\vb{x_0}$
        \item Se $\vecf$ è derivabile in $\vb{x_0} \in A$ e le derivate parziali sono tutte continue in $\vb{x_0}$, allora $\vecf$ è differenziabile
        \qed
    \end{enumerate}
\end{theorem}

\begin{theorem}
    [di differenziabilità della funzione composta]
    Siano $A\subseteq \R^n, B \subseteq \R^k$ aperti. Siano $\vecf: A \to B$ differenziabile in $\vb{x_0} \in A$ e $\bm g:B \to \R^l$ differenziabile in $\vb{y_0} = \vecf(\vb{x_0})$, allora $\bm g \circ \vecf : A \to \R^l$ è differenziabile in $\vb{x_0}$ e $J_{\bm g \circ \vecf}(\vb{x_0})=J_{\bm g}(\vecf (\vb{x_0}))\cdot J_{\vecf}(\vb{x_0}) \in \mathcal{M}_{l\times n}$.
    \qed
\end{theorem}

\begin{definition}
    [Diffeomorfismo]
    Siano $A,B \subseteq \R^n$ aperti. La funzione $\vecf: A \to B$ è un diffeomorfismo $C^{(k)}$ se $\vecf$ è iniettiva e suriettiva e $\vecf, \vecf^{-1}$ sono $C^{(k)}$ nei rispettivi domini.
\end{definition}

\begin{theorem}
    [Differenziale della funzione inversa]
    Siano $A,B \subseteq \R^n$ aperti e sia $\vecf:A\to B \in C^{(1)}$. Allora vale che
    \begin{equation*}
        J_{\vecf^{-1}}(\vb{y}) = \left(J_{\vecf}(\vecf^{-1}(\vb{y})) \right)^{-1} \ \forall \vb{y} \in B
    \end{equation*}
\end{theorem}

\begin{proof}
    
\end{proof}

\section{Varietà regolari}

\begin{definition}
    [Varietà regolare $(n-k)$-dimensionale]
    Siano $A \subseteq \R^n$, $\bm g=(g_1,\dots,g_k):A\to\R^k \in C^{(1)}$. Detto $\Gamma =\{\vb{x}\in A : g_1(\vb{x})=0,\dots,g_k(\vb{x})=0\}$ l'insieme delle soluzioni del sistema di equazioni, $\Gamma$ è una varietà regolare $(n-k)$-dimensionale se $\forall \vb{x} \in \Gamma \ J_{\bm g}(\vb{x})$ ha rango uguale a $k$.
\end{definition}

\begin{definition}
    [Vettore tangente]
    Il vettore $\vb{h} \in \R^n$ è tangente a $\Gamma$ in $\vb{x_0}$ se $\exists \varphi: (-\varepsilon, \varepsilon) \to \Gamma \subseteq \R^n$ di classe $C^{(1)} \tc \varphi (0) = \vb{x_0} \e \varphi ' (0) = \vb{h}$.
\end{definition}

\begin{definition}
    [Spazio tangente]
    Se $\Gamma$ è una varietà regolare $(n-k)$-dimensionale e $\vb{x_0} \in \Gamma$, si definisce lo spazio tangente come segue:
    \begin{equation*}
        T_{\vb{x_0}}\Gamma = \{ \vb{h}=(h_1,\dots,h_n) \in \R^n : \innerproduct{\grad g_1(\vb{x_0)}}{\vb{h}}=0,\dots,\innerproduct{\grad g_k(\vb{x_0)}}{\vb{h}}=0 \}
    \end{equation*}
\end{definition}

\begin{remark}
    Si noti che $\grad g_1(\vb{x_0}),\dots,\grad g_k (\vb{x_0})$ costituisce un sistema di vettori linearmente indipendenti perché $\rk(J_{\bm g})=k \ \forall \vb{x} \in \Gamma$. Per questo motivo, $\dim T_{\vb{x_0}}\Gamma= n-k$.
\end{remark}

\begin{definition}
    [Spazio normale]
    Se $\Gamma$ è una varietà regolare $(n-k)$-dimensionale e $\vb{x_0} \in \Gamma$, si definisce lo spazio normale come segue:
    \begin{equation*}
        N_{\vb{x_0}}\Gamma = \left\{ \vb{h}=(h_1,\dots,h_n) \in \R^n : \exists \lambda_1, \dots, \lambda_k \in \R \e \vb{h}=\sum_{j=1}^n \lambda_j \grad g_j(\vb{x_0}) \right\}
    \end{equation*}
    Si noti che $\dim N_{\vb{x_0}}\Gamma = k$.
\end{definition}

\begin{definition}
    [Iperpiano tangente]
    A partire dalla nozione di spazio tangente si può definire l'iperpiano tangente nel punto $\vb{x_0}$, che è costituito dall'insieme dei punti $\vb{x}$ tali che il loro vettore distanza dal punto $\vb{x_0}$ appartenga allo spazio tangente a $\Gamma$:
    \begin{equation*}
        I= \{ \vb{x} \in \R^n :  \innerproduct{\grad g_1(\vb{x_0)}}{\vb{x}-\vb{x_0}}=0,\dots,\innerproduct{\grad g_k(\vb{x_0)}}{\vb{x}-\vb{x_0}}=0 \}
    \end{equation*}
\end{definition}

\section{Teorema di Dini}

\begin{theorem}
    [Caso con $1$ equazione in $2$ incognite]
    Sia $A \subseteq \R^2$ aperto, $g \in C^{(1)}(A, \R)$ e $(x_0,y_0) \in A \tc g(x_0, y_0)=0 \e \partial_y g(x_0,y_0)\neq 0$.
    Allora,
    \begin{enumerate}
        \item $\exists \delta, \varepsilon>0 \tc W=[x_0-\delta,x_0+\delta]\times[y_0-\varepsilon,y_0+\varepsilon] \subseteq A$
        \item $\exists f \in C^{(1)}([x_0-\delta,x_0+\delta],[y_0-\varepsilon,y_0+\varepsilon]) \tc g(x,y)=0 \with (x,y) \in W \iff y=f(x) \with x \in [x_0-\delta,x_0+\delta]$
    \end{enumerate}
    In altre parole, se si restringe l'equazione $g(x,y)=0$ al rettangolo $W$ l'insieme delle sue soluzioni è il grafico di $f$. Inoltre
    \begin{equation*}
        \frac{df}{dx}(x)=-\frac{\partial_x g(x,f(x))}{\partial_y g(x,f(x))}
    \end{equation*}
\end{theorem}

\begin{proof}
    [Dimostrazione per $n=2$ e $k=1$.]
\end{proof}

\begin{theorem}
    [Caso generale con $k$ equazioni in $n$ incognite]
    Siano $A\subseteq \R^n$ aperto, $\bm g \in C^{(1)}(A,\R^k)$, $(\vb{x^0}, \vb{y^0})=(x_1^0,\dots,x_{n-k}^0,y_1^0,\dots,y_{k}^0) \in A \tc \bm g(\vb{x^0}, \vb{y^0})=\vb{0} \e$
    \begin{equation*}
        \det\frac{\partial(g_1\cdots g_k)}{\partial (y_1 \cdots y_k)}(\vb{x^0}, \vb{y^0})=\\
        \det\begin{bmatrix}
            \frac{\partial g_1}{\partial y_1} & \cdots & \frac{\partial g_1}{\partial y_k}\\
            \vdots & \ddots & \vdots \\
            \frac{\partial g_k}{\partial y_1} & \cdots & \frac{\partial g_k}{\partial y_k}
        \end{bmatrix}
        (\vb{x^0}, \vb{y^0}) \neq 0
    \end{equation*}
    Allora esistono $I_{\vb{x^0}} \in \R^{n-k}$ intorno circolare aperto di $\vb{x^0}$ e $J_{\vb{y^0}} \in \R^k$ intorno circolare aperto di $\vb{y^0}$ tali che:
    \begin{enumerate}
        \item $W=I_{\vb{x^0}}\times J_{\vb{y^0}} \subseteq A$
        \item $\exists \vecf \in C^{(1)}(I_{\vb{x^0}}, J_{\vb{y^0}}) \tc \bm g(\vb{x}, \vb{y})=\vb{0} \iff \vb{y} = \bm f (\vb{x}) \with \vb{x} \in I_{\vb{x^0}}$
    \end{enumerate}
    Inoltre
    \begin{equation*}
        \frac{\partial f_i}{\partial x_j}(\vb{x})=-\frac
        {\det \frac{\partial (g_1,\dots,g_k)}{\partial y_1,\dots,y_{i-1},x_j,y_{i+1},\dots,y_k}(\vb{x},\bm f(\vb{x}))}
        {\det \frac{\partial (g_1,\dots,g_k)}{\partial y_1,\dots,y_k}(\vb{x},\bm f(\vb{x}))}
    \end{equation*}
    \qed
\end{theorem}

\section{Estremanti condizionati}

\begin{definition}
    [Punto estremante condizionato]
    Siano $A\subseteq\R^n$ aperto, $\Gamma \subseteq A$ una varietà regolare $(n-k)$-dimensionale e $f: A\to\R$. Il punto $\vb{x_0} \in \Gamma$ è un punto di minimo (massimo) locale per $f$ ristretta a $\Gamma$ se $\exists \varepsilon > 0 \tc f(\vb{x}) \geq f(\vb{x_0}) \ (f(\vb{x}) \leq f(\vb{x_0})) \ \forall \vb{x} \in \Gamma \cap B_\varepsilon(\vb{x_0})$.
\end{definition}

\begin{definition}
    [Punto critico condizionato]
    Siano $A\subseteq\R^n$ aperto, $\Gamma \subseteq A$ una varietà regolare $(n-k)$-dimensionale e $f: A\to\R$. Il punto $\vb{x_0} \in \Gamma$ è punto critico condizionato per $f$ ristretta a $\Gamma$ se $\forall \bm{\hat{\nu}} \in T_{\vb{x_0}}\Gamma, \ \displaystyle\frac{\partial f}{\partial \bm{\hat{\nu}}}(\vb{x_0})=0$. 
\end{definition}

\begin{theorem}
    [di Fermat condizionato]\label{thm:fermat_cond}
    Siano $A\subseteq\R^n$ aperto, $\Gamma \subseteq A$ una varietà regolare $(n-k)$-dimensionale e $f: A\to\R$. Se $\vb{x_0} \in \Gamma$ è punto estremante condizionato per $f$ a $\Gamma$, allora $\vb{x_0}$ è un punto critico condizionato per $f$ a $\Gamma$.
\end{theorem}

\begin{proof}
    
\end{proof}

\begin{corollary}
    Sotto le ipotesi del teorema \ref{thm:fermat_cond}, $\grad f (\vb{x_0}) \in N_{\vb{x_0}}\Gamma$.
    \qed
\end{corollary}

\begin{definition}
    [Funzione di Lagrange]
    Per lo studio dei punti critici condizionati di $f: A\to \R$ alla varietà regolare $\Gamma$ definita dall'equazione $\bm g (\vb{x})=\vb{0}$ si definisce la funzione di Lagrange, o lagrangiana:
    \begin{equation*}
        \displaystyle \mathcal{L}(\vb{x};\lambda_1,\dots,\lambda_k)=f(\vb{x})-\sum_{j=1}^k \lambda_j g_j(\vb{x}) : A \times \R^k \to \R
    \end{equation*}
\end{definition}

\begin{theorem}
    [dei moltiplicatori di Lagrange]
    Siano $f,g_1,\dots,g_k \in C^{(1)}(A\subseteq\R^n, \R) \with A$ aperto in $\R^n$. Se $\Gamma = \{ \vb{x} \in A: g_1 (\vb{x})=0, \dots, g_k(\vb{x})=0 \}$ è una varietà regolare e $\vb{x_0} \in \Gamma$ è punto estremante condizionato di $f$ a $\Gamma$, allora $\exists (\overline{\lambda}_1, \dots,\overline{\lambda}_k)$ tale che il punto $(\vb{x_0}; \overline{\lambda}_1,\dots,\overline{\lambda}_k)$ è punto critico libero di $\mathcal{L}$.
\end{theorem}

\begin{proof}
    
\end{proof}

\begin{theorem}
    [Condizioni con funzione di Lagrange]
    Siano $f,g_1,\dots,g_k \in C^{(2)}(A\subseteq\R^n, \R) \with A$ aperto e $\Gamma = \{ \vb{x} \in A: g_1 (\vb{x})=0, \dots, g_k(\vb{x})=0 \}$ una varietà regolare.
    \begin{enumerate}
        \item Se $\vb{x_0} \in \Gamma$ è punto di minimo condizionato di $f$ a $\Gamma$, allora $\exists \overline{\lambda}_1,\dots,\overline{\lambda}_k \in \R \tc$
        \begin{enumerate}[a.]
            \item $\grad f(\vb{x_0})=\displaystyle \sum_{j=1}^k \overline{\lambda}_j \grad g_j(\vb{x_0})$
            \item $\innerproduct{\vb{h}}{\left( H_f(\vb{x_0})-\sum_{j=1}^k\overline{\lambda}_j H_{g_j}(\vb{x_0}) \right)\vb{h}} \geq 0 \ \forall \vb{h} \in T_{\vb{x_0}}\Gamma$, ovvero la restrizione della forma quadratica associata alla matrice $\left( H_f(\vb{x_0})-\sum_{j=1}^k\overline{\lambda}_j H_{g_j}(\vb{x_0}) \right)$ allo spazio $T_{\vb{x_0}}\Gamma$ è definita positiva o semidefinita positiva 
        \end{enumerate}
        \item Se $\vb{x_0} \in \Gamma$ soddisfa per una qualche scelta di $(\overline{\lambda}_1,\dots,\overline{\lambda}_k)$:
        \begin{enumerate}[a.]
            \item $\grad f(\vb{x_0})=\displaystyle\sum_{j=1}^k\overline{\lambda}_j \grad g_j (\vb{x_0})$
            \item $\innerproduct{\vb{h}}{\left( H_f(\vb{x_0})-\sum_{j=1}^k\overline{\lambda}_j H_{g_j}(\vb{x_0}) \right)\vb{h}} > 0 \ \forall \vb{h} \in T_{\vb{x_0}}\Gamma$
        \end{enumerate}
        allora $\vb{x_0}$ è punto di minimo condizionato di $f$ a $\Gamma$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    [Dimostrazione del punto 2.]
\end{proof}